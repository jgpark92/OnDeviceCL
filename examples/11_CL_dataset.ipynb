{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "dataName = \"KU-HAR\"\n",
    "#maxClassNum = 20\n",
    "\n",
    "data_path = \"../Data/\" + dataName\n",
    "save_path = \"../Data/\" + dataName + \"/deploy\"\n",
    "train_X = np.load(data_path+'/train_x.npy').transpose(0,2,1)\n",
    "train_Y = np.load(data_path+'/train_y.npy')\n",
    "train_Y = tf.keras.utils.to_categorical(train_Y)\n",
    "test_X = np.load(data_path+'/test_x.npy').transpose(0,2,1)\n",
    "test_Y = np.load(data_path+'/test_y.npy')\n",
    "test_Y = tf.keras.utils.to_categorical(test_Y)\n",
    "\n",
    "# np.save(save_path + \"/train_x.npy\", train_X)\n",
    "# np.save(save_path + \"/train_y.npy\", train_Y)\n",
    "# np.save(save_path + \"/test_x.npy\", test_X)\n",
    "# np.save(save_path + \"/test_y.npy\", test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11578, 300, 6)\n",
      "(940, 18)\n",
      "(1527, 18)\n",
      "(456, 18)\n",
      "(1043, 18)\n",
      "(980, 18)\n"
     ]
    }
   ],
   "source": [
    "initial_idx = np.where(train_Y[:,:8].sum(axis=1) == 1)\n",
    "train_X0 = train_X[initial_idx]\n",
    "Y0 = train_Y[initial_idx]\n",
    "\n",
    "train_Y0 = np.zeros((Y0.shape[0], 20), dtype=np.float32)\n",
    "train_Y0[:,:]\n",
    "\n",
    "idx = np.where(train_Y[:,8:10].sum(axis=1) == 1)\n",
    "train_X1 = train_X[idx]\n",
    "train_Y1 = train_Y[idx]\n",
    "\n",
    "idx = np.where(train_Y[:,10:12].sum(axis=1) == 1)\n",
    "train_X2 = train_X[idx]\n",
    "train_Y2 = train_Y[idx]\n",
    "\n",
    "idx = np.where(train_Y[:,12:14].sum(axis=1) == 1)\n",
    "train_X3 = train_X[idx]\n",
    "train_Y3 = train_Y[idx]\n",
    "\n",
    "idx = np.where(train_Y[:,14:16].sum(axis=1) == 1)\n",
    "train_X4 = train_X[idx]\n",
    "train_Y4 = train_Y[idx]\n",
    "\n",
    "idx = np.where(train_Y[:,16:18].sum(axis=1) == 1)\n",
    "train_X5 = train_X[idx]\n",
    "train_Y5 = train_Y[idx]\n",
    "\n",
    "\n",
    "print(train_X0.shape)\n",
    "print(train_Y1.shape)\n",
    "print(train_Y2.shape)\n",
    "print(train_Y3.shape)\n",
    "print(train_Y4.shape)\n",
    "print(train_Y5.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2931, 18)\n",
      "(3137, 18)\n",
      "(3497, 18)\n",
      "(3617, 18)\n",
      "(3872, 18)\n",
      "(4131, 18)\n"
     ]
    }
   ],
   "source": [
    "initial_idx = np.where(test_Y[:,:8].sum(axis=1) == 1)\n",
    "test_X0 = test_X[initial_idx]\n",
    "test_Y0 = test_Y[initial_idx]\n",
    "\n",
    "idx = np.where(test_Y[:,:10].sum(axis=1) == 1)\n",
    "test_X1 = test_X[idx]\n",
    "test_Y1 = test_Y[idx]\n",
    "\n",
    "idx = np.where(test_Y[:,:12].sum(axis=1) == 1)\n",
    "test_X2 = test_X[idx]\n",
    "test_Y2 = test_Y[idx]\n",
    "\n",
    "idx = np.where(test_Y[:,:14].sum(axis=1) == 1)\n",
    "test_X3 = test_X[idx]\n",
    "test_Y3 = test_Y[idx]\n",
    "\n",
    "idx = np.where(test_Y[:,:16].sum(axis=1) == 1)\n",
    "test_X4 = test_X[idx]\n",
    "test_Y4 = test_Y[idx]\n",
    "\n",
    "test_X5 = test_X\n",
    "test_Y5 = test_Y\n",
    "\n",
    "print(test_Y0.shape)\n",
    "print(test_Y1.shape)\n",
    "print(test_Y2.shape)\n",
    "print(test_Y3.shape)\n",
    "print(test_Y4.shape)\n",
    "print(test_Y5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(save_path + \"/train_x0.npy\", train_X0)\n",
    "np.save(save_path + \"/train_y0.npy\", train_Y0)\n",
    "np.save(save_path + \"/train_x1.npy\", train_X1)\n",
    "np.save(save_path + \"/train_y1.npy\", train_Y1)\n",
    "np.save(save_path + \"/train_x2.npy\", train_X2)\n",
    "np.save(save_path + \"/train_y2.npy\", train_Y2)\n",
    "np.save(save_path + \"/train_x3.npy\", train_X3)\n",
    "np.save(save_path + \"/train_y3.npy\", train_Y3)\n",
    "np.save(save_path + \"/train_x4.npy\", train_X4)\n",
    "np.save(save_path + \"/train_y4.npy\", train_Y4)\n",
    "np.save(save_path + \"/train_x5.npy\", train_X5)\n",
    "np.save(save_path + \"/train_y5.npy\", train_Y5)\n",
    "\n",
    "np.save(save_path + \"/test_x0.npy\", test_X0)\n",
    "np.save(save_path + \"/test_y0.npy\", test_Y0)\n",
    "np.save(save_path + \"/test_x1.npy\", test_X1)\n",
    "np.save(save_path + \"/test_y1.npy\", test_Y1)\n",
    "np.save(save_path + \"/test_x2.npy\", test_X2)\n",
    "np.save(save_path + \"/test_y2.npy\", test_Y2)\n",
    "np.save(save_path + \"/test_x3.npy\", test_X3)\n",
    "np.save(save_path + \"/test_y3.npy\", test_Y3)\n",
    "np.save(save_path + \"/test_x4.npy\", test_X4)\n",
    "np.save(save_path + \"/test_y4.npy\", test_Y4)\n",
    "np.save(save_path + \"/test_x5.npy\", test_X5)\n",
    "np.save(save_path + \"/test_y5.npy\", test_Y5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
