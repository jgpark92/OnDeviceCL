{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"CLI wrapper for tflite_transfer_converter.\n",
    "\n",
    "Converts a TF model to a TFLite transfer learning model.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "INPUT_CHANNELS = 6\n",
    "SEG_SIZE = 300\n",
    "NUM_FEATURES = 1 * 1 * 128\n",
    "MAX_CLASSES = 18 # new activity가 들어올때마다 모델 구조를 바꾸는게 시간이 더 걸림 그냥 적절한 맥시멈 헤드 수를 정해놓고 마스킹\n",
    "NUM_NEW_CLASSES = 2\n",
    "\n",
    "\n",
    "class OnDeviceLearningModel(tf.Module):\n",
    "  \"\"\"On-Device CL model class.\"\"\"\n",
    "\n",
    "  def __init__(self, backbone, initial_out, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    :param backbone: non-trainable feature extractor\n",
    "    :param initial_out: the number of initial classes\n",
    "    \"\"\"\n",
    "\n",
    "    self.num_features = NUM_FEATURES\n",
    "    self.max_heads = MAX_CLASSES\n",
    "    self.num_classes = initial_out\n",
    "    self.mask_value = -1000\n",
    "\n",
    "    # masking\n",
    "    self.active_units = tf.Variable(tf.zeros(self.max_heads, dtype=tf.bool))\n",
    "    self.active_units[:self.num_classes].assign(True)\n",
    "\n",
    "    # trainable weights and bias for softmax\n",
    "    self.ws = tf.Variable(\n",
    "        tf.zeros((self.num_features, self.max_heads)),\n",
    "        name='ws',\n",
    "        trainable=True)\n",
    "    self.bs = tf.Variable(\n",
    "        tf.zeros((1, self.max_heads)), name='bs', trainable=True)\n",
    "\n",
    "    # base model\n",
    "    self.base = backbone\n",
    "    # loss function and optimizer\n",
    "    self.loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "    self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "  @tf.function(input_signature=[])\n",
    "  def adapt(self):\n",
    "    self.num_classes += NUM_NEW_CLASSES\n",
    "    self.active_units[:self.num_classes].assign(True)\n",
    "    return True\n",
    "\n",
    "  @tf.function(input_signature=[\n",
    "      tf.TensorSpec([None, SEG_SIZE, INPUT_CHANNELS], tf.float32),\n",
    "  ])\n",
    "  def load(self, feature):\n",
    "    \"\"\"Generates and loads bottleneck features from the given image batch.\n",
    "\n",
    "    Args:\n",
    "      feature: A tensor of image feature batch to generate the bottleneck from.\n",
    "\n",
    "    Returns:\n",
    "      Map of the bottleneck.\n",
    "    \"\"\"\n",
    "    bottleneck = tf.reshape(\n",
    "        self.base(feature, training=False), (-1, self.num_features))\n",
    "    return {'bottleneck': bottleneck}\n",
    "\n",
    "\n",
    "  @tf.function(input_signature=[\n",
    "      tf.TensorSpec([None, NUM_FEATURES], tf.float32),\n",
    "      tf.TensorSpec([None, MAX_CLASSES], tf.float32),\n",
    "  ])\n",
    "  def train(self, bottleneck, label):\n",
    "    \"\"\"Runs one training step with the given bottleneck features and labels.\n",
    "\n",
    "    Args:\n",
    "      bottleneck: A tensor of bottleneck features generated from the base model.\n",
    "      label: A tensor of class labels for the given batch.\n",
    "\n",
    "    Returns:\n",
    "      Map of the training loss.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "      logits = tf.matmul(bottleneck, self.ws) + self.bs\n",
    "      #mask = tf.logical_not(self.active_units)\n",
    "      #logits = tf.mask_fill(mask=mask, value=self.mask_value)\n",
    "      logits = tf.where(self.active_units, logits, self.mask_value)\n",
    "      prediction = tf.nn.softmax(logits)\n",
    "      loss = self.loss_fn(prediction, label)\n",
    "    gradients = tape.gradient(loss, [self.ws, self.bs])\n",
    "    self.optimizer.apply_gradients(zip(gradients, [self.ws, self.bs]))\n",
    "    result = {'loss': loss}\n",
    "    for grad in gradients:\n",
    "      result[grad.name] = grad\n",
    "    return result\n",
    "\n",
    "  @tf.function(input_signature=[\n",
    "      tf.TensorSpec([None, SEG_SIZE, INPUT_CHANNELS], tf.float32)\n",
    "  ])\n",
    "  def infer(self, feature):\n",
    "    \"\"\"Invokes an inference on the given feature.\n",
    "\n",
    "    Args:\n",
    "      feature: A tensor of image feature batch to invoke an inference on.\n",
    "\n",
    "    Returns:\n",
    "      Map of the softmax output.\n",
    "    \"\"\"\n",
    "    bottleneck = tf.reshape(\n",
    "        self.base(feature, training=False), (-1, self.num_features))\n",
    "    logits = tf.matmul(bottleneck, self.ws) + self.bs\n",
    "    logits = tf.where(self.active_units, logits, self.mask_value)\n",
    "    return {'output': tf.nn.softmax(logits)}\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "  def save(self, checkpoint_path):\n",
    "    \"\"\"Saves the trainable weights to the given checkpoint file.\n",
    "\n",
    "    Args:\n",
    "      checkpoint_path: A file path to save the model.\n",
    "\n",
    "    Returns:\n",
    "      Map of the checkpoint file path.\n",
    "    \"\"\"\n",
    "    tensor_names = [self.ws.name, self.bs.name]\n",
    "    tensors_to_save = [self.ws.read_value(), self.bs.read_value()]\n",
    "    tf.raw_ops.Save(\n",
    "        filename=checkpoint_path,\n",
    "        tensor_names=tensor_names,\n",
    "        data=tensors_to_save,\n",
    "        name='save')\n",
    "    return {'checkpoint_path': checkpoint_path}\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "  def restore(self, checkpoint_path):\n",
    "    \"\"\"Restores the serialized trainable weights from the given checkpoint file.\n",
    "\n",
    "    Args:\n",
    "      checkpoint_path: A path to a saved checkpoint file.\n",
    "\n",
    "    Returns:\n",
    "      Map of restored weight and bias.\n",
    "    \"\"\"\n",
    "    restored_tensors = {}\n",
    "    restored = tf.raw_ops.Restore(\n",
    "        file_pattern=checkpoint_path,\n",
    "        tensor_name=self.ws.name,\n",
    "        dt=np.float32,\n",
    "        name='restore')\n",
    "    self.ws.assign(restored)\n",
    "    restored_tensors['ws'] = restored\n",
    "    restored = tf.raw_ops.Restore(\n",
    "        file_pattern=checkpoint_path,\n",
    "        tensor_name=self.bs.name,\n",
    "        dt=np.float32,\n",
    "        name='restore')\n",
    "    self.bs.assign(restored)\n",
    "    restored_tensors['bs'] = restored\n",
    "    return restored_tensors\n",
    "\n",
    "  @tf.function(input_signature=[])\n",
    "  def initialize_weights(self):\n",
    "    \"\"\"Initializes the weights and bias of the head model.\n",
    "\n",
    "    Returns:\n",
    "      Map of initialized weight and bias.\n",
    "    \"\"\"\n",
    "    self.ws.assign(tf.random.uniform((self.num_features, self.max_heads)))\n",
    "    self.bs.assign(tf.random.uniform((1, self.max_heads)))\n",
    "    return {'ws': self.ws, 'bs': self.bs}\n",
    "\n",
    "\n",
    "def convert_and_save(backbone, init_out, saved_model_dir='saved_model'):\n",
    "  \"\"\"Converts and saves the TFLite Transfer Learning model.\n",
    "\n",
    "  Args:\n",
    "    saved_model_dir: A directory path to save a converted model.\n",
    "  \"\"\"\n",
    "  model = OnDeviceLearningModel(backbone, init_out)\n",
    "\n",
    "  tf.saved_model.save(\n",
    "      model,\n",
    "      saved_model_dir,\n",
    "      signatures={\n",
    "          'load': model.load.get_concrete_function(),\n",
    "          'train': model.train.get_concrete_function(),\n",
    "          'infer': model.infer.get_concrete_function(),\n",
    "          'save': model.save.get_concrete_function(),\n",
    "          'restore': model.restore.get_concrete_function(),\n",
    "          'initialize': model.initialize_weights.get_concrete_function(),\n",
    "          'adapt': model.adapt.get_concrete_function(),\n",
    "      })\n",
    "\n",
    "  # Convert the model\n",
    "  converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "  converter.target_spec.supported_ops = [\n",
    "      tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "      tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "  ]\n",
    "  converter.experimental_enable_resource_variables = True\n",
    "  tflite_model = converter.convert()\n",
    "\n",
    "  model_file_path = os.path.join('model.tflite')\n",
    "  with open(model_file_path, 'wb') as model_file:\n",
    "    model_file.write(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n",
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_2703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_2719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "  loadModel = tf.keras.models.load_model(\"pretrained\")\n",
    "#   model = OnDeviceLearningModel(loadModel.backbone, )\n",
    "  \n",
    "#   print(type(model.ws))\n",
    "#   model.adapt()\n",
    "#   print(type(model.ws))\n",
    "#   print(model.ws.read_value().shape)\n",
    "  convert_and_save(loadModel.backbone, 8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
